<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AWS Machine Learning Engineering Course</title>
    <link rel="stylesheet" href="ml.styles.css" />
    <script src="scriptml.js" defer></script>
  </head>
  <body>
    <h1>AWS Machine Learning Engineering Course (ML-C01)</h1>

    <div fclass="section">
      <h2>Section 1: Introduction</h2>
      <div class="lesson">
        <h3>Lesson 1: How to Use This Course</h3>
        <p>
          Welcome to the AWS Machine Learning Engineering course! This
          comprehensive program will guide you through building expertise in
          machine learning on AWS.
        </p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            This course is structured like a full-stack development journey, but
            for machine learning. You'll learn about:
          </p>
          <ul>
            <li>Core ML algorithms and their mathematical foundations</li>
            <li>AWS's ML service architecture and implementation patterns</li>
            <li>Hands-on experience with production-grade ML tools</li>
            <li>Best practices for scalable ML systems design</li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>
            Imagine you're building a robot that can learn! This course will
            teach you:
          </p>
          <ul>
            <li>
              How to make computers learn from examples (just like how you learn
              from practice!)
            </li>
            <li>Using Amazon's special tools to build smart programs</li>
            <li>
              Making your computer recognize pictures, understand words, and
              make predictions
            </li>
            <li>How to make your robot helper work better and faster</li>
          </ul>
        </div>
        <p>Key Resources:</p>
        <ul>
          <li>
            <a
              href="https://docs.aws.amazon.com/sagemaker/latest/dg/gs.html"
              class="aws-link"
              >Getting Started with Amazon SageMaker</a
            >
          </li>
          <li>
            <a
              href="https://aws.amazon.com/training/learn-about/machine-learning/"
              class="aws-link"
              >AWS Machine Learning Training and Certification</a
            >
          </li>
          <li>
            <a
              href="https://aws.amazon.com/whitepapers/?whitepapers-main.sort-by=item.additionalFields.sortDate&whitepapers-main.sort-order=desc&awsf.whitepapers-content-type=*all&awsf.whitepapers-tech-category=tech-category%23ai-ml"
              class="aws-link"
              >AWS ML Whitepapers</a
            >
          </li>
        </ul>
      </div>

      <div class="lesson">
        <h3>Lesson 2: Domain 2 Introduction</h3>
        <p>Master the core concepts of machine learning on AWS:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            Think of ML as a programming paradigm where instead of writing
            explicit rules, you're designing systems that learn patterns from
            data:
          </p>
          <ul>
            <li>
              Supervised Learning: Like function approximation where f(x) = y,
              learning from labeled examples
            </li>
            <li>
              Unsupervised Learning: Pattern discovery in unlabeled data using
              clustering and dimensionality reduction
            </li>
            <li>
              AWS ML Stack: A three-tier architecture with high-level AI
              Services, managed ML with SageMaker, and low-level infrastructure
            </li>
            <li>
              MLOps: Applying DevOps principles to ML system lifecycles,
              including version control for data and models
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Let's learn how to make computers smart!</p>
          <ul>
            <li>
              Teaching computers by showing them examples (like teaching a dog
              tricks)
            </li>
            <li>
              Using Amazon's special tools that make it easier to build smart
              programs
            </li>
            <li>
              Learning how to prepare information so computers can understand it
            </li>
            <li>Making sure our smart programs keep working well over time</li>
          </ul>
        </div>
        <p>Essential Reading:</p>
        <ul>
          <li>
            <a
              href="https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html"
              class="aws-link"
              >What is Amazon SageMaker?</a
            >
          </li>
          <li>
            <a
              href="https://aws.amazon.com/machine-learning/mlops/"
              class="aws-link"
              >AWS MLOps Framework</a
            >
          </li>
        </ul>
      </div>

      <div class="lesson">
        <h3>Lesson 3: Course Overview</h3>
        <p>The course is structured to provide:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>This course follows a bottom-up approach to ML engineering:</p>
          <ul>
            <li>
              Mathematical Foundations: Linear algebra, calculus, and
              probability theory applied to ML
            </li>
            <li>
              Algorithm Implementation: From scratch implementations to using
              optimized libraries
            </li>
            <li>System Design: Architecting end-to-end ML pipelines on AWS</li>
            <li>
              Production Deployment: Load balancing, scaling, and monitoring ML
              systems
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>We'll learn step by step, like building with LEGO blocks:</p>
          <ul>
            <li>
              First, we'll learn the basic building blocks of making computers
              smart
            </li>
            <li>Then, we'll play with Amazon's cool tools to build things</li>
            <li>
              We'll solve real problems, like teaching computers to recognize
              cats and dogs
            </li>
            <li>
              Finally, we'll learn the best ways to make our creations work
              perfectly!
            </li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 4: Choosing a Modeling Approach</h3>
        <p>
          Learn to select the optimal modeling approach based on your use case:
        </p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            Model selection is a critical engineering decision that involves
            multiple trade-offs:
          </p>
          <ul>
            <li>
              Problem Types: Understanding the mathematical foundations of
              classification (decision boundaries), regression (function
              approximation), clustering (distance metrics), and time series
              (sequence modeling)
            </li>
            <li>
              Data Analysis: Evaluating data distribution, feature engineering
              requirements, and statistical properties
            </li>
            <li>
              Model Complexity: Balancing model capacity with computational
              constraints and avoiding overfitting
            </li>
            <li>
              Production Considerations: Analyzing inference latency, resource
              utilization, and scaling requirements
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Let's learn how to pick the right tool for each job!</p>
          <ul>
            <li>
              Some problems are like sorting things into groups (like sorting
              toys), while others are about guessing numbers (like guessing
              someone's age)
            </li>
            <li>
              We need to check if we have enough good information to teach our
              computer
            </li>
            <li>
              Sometimes simpler solutions work better than complicated ones
            </li>
            <li>
              We need to make sure our computer can work fast enough to be
              helpful
            </li>
          </ul>
        </div>
        <p>Reference Materials:</p>
        <ul>
          <li>
            <a
              href="https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-choose.html"
              class="aws-link"
              >Choosing an Algorithm</a
            >
          </li>
          <li>
            <a
              href="https://d1.awsstatic.com/whitepapers/machine-learning-foundations.pdf"
              class="aws-link"
              >Machine Learning Foundations Whitepaper</a
            >
          </li>
        </ul>
      </div>
    </div>

    <div class="section">
      <h2>Section 2: Training Model</h2>
      <div class="lesson">
        <h3>Lesson 3: Model Training Concepts</h3>
        <p>Understanding fundamental model training concepts:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Core concepts in model training architecture:</p>
          <ul>
            <li>
              Training Pipeline Design: Data preprocessing, feature engineering,
              and model configuration
            </li>
            <li>
              Optimization Algorithms: Gradient descent variants, learning rate
              scheduling, and regularization
            </li>
            <li>
              Distributed Training: Parameter servers, data parallelism, and
              model parallelism
            </li>
            <li>
              Model Evaluation: Cross-validation, metrics computation, and early
              stopping
            </li>
          </ul>
          <h4>Simple Explanation:</h4>
          <p>Let's learn how to teach our computer!</p>
          <ul>
            <li>Preparing information in a way computers can understand</li>
            <li>Helping computers learn from their mistakes</li>
            <li>Using multiple computers to learn faster</li>
            <li>Checking how well our computer is learning</li>
          </ul>
          <h4>Model Training Concepts:</h4>
          <p>Understanding optimization algorithms for model training:</p>
          <ul>
            <li>
              Gradient Descent: An iterative optimization algorithm that
              minimizes the loss function by updating model parameters in the
              direction of the steepest descent of the gradient. It processes
              the entire dataset in each iteration, making it computationally
              expensive for large datasets.
            </li>
            <li>
              Stochastic Gradient Descent (SGD): A variation of gradient descent
              that updates parameters using a single randomly selected data
              point in each iteration. While introducing more noise, SGD is much
              faster and can help escape local minima.
            </li>
            <li>
              Mini-batch Gradient Descent: A compromise between full gradient
              descent and SGD that updates parameters using small random batches
              of data points. This approach balances computational efficiency
              with update stability.
            </li>
            <li>
              Loss Functions: Mathematical functions that quantify the
              difference between predicted and actual values. Common examples
              include Mean Squared Error for regression and Cross-Entropy for
              classification.
            </li>
            <li>
              Log-Likelihood Loss: A probabilistic loss function that maximizes
              the likelihood of observing the training data given the model
              parameters. Often used in classification problems and expressed as
              negative log-likelihood to convert maximization to minimization.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>How Computers Learn:</h4>
          <p>Understanding how computers improve their learning:</p>
          <ul>
            <li>
              Gradient Descent: The computer looks at all examples at once and
              takes small steps to get better, like studying an entire textbook
              before making any changes to your understanding.
            </li>
            <li>
              Stochastic Gradient Descent: The computer looks at just one
              example at a time and makes quick adjustments, like learning from
              each page of a book immediately.
            </li>
            <li>
              Mini-batch Gradient Descent: The computer looks at small groups of
              examples and then adjusts, like studying one chapter at a time.
            </li>
            <li>
              Loss Functions: Special ways to measure mistakes, like a score
              that shows how wrong the computer's guesses are.
            </li>
            <li>
              Log-Likelihood Loss: A special measuring tool that helps the
              computer understand how confident it should be in its answers.
            </li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 4: Compute Environment Selection</h3>
        <p>Choose the right compute environment for training:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Understanding compute infrastructure options:</p>
          <ul>
            <li>
              Instance Types: CPU vs GPU optimization, memory-to-compute ratios
            </li>
            <li>
              Distributed Computing: Multi-node training, network bandwidth
              considerations
            </li>
            <li>
              Cost Optimization: Spot instances, automatic scaling, resource
              monitoring
            </li>
            <li>
              Environment Management: Container orchestration, dependency
              management
            </li>
          </ul>
          <!-- Additional detailed notes for ML engineering students -->
          <h4>Detailed AWS Compute Environment Notes:</h4>
          <p>
            Key considerations for selecting optimal training infrastructure:
          </p>
          <ul>
            <li>
              <strong>CPU Instances (C-type):</strong> Ideal for traditional ML
              algorithms (XGBoost, Random Forest), data preprocessing, and
              inference workloads with low parallelization requirements.
              Consider c5/c6g instances for cost-effective training of
              small-to-medium models.
            </li>
            <li>
              <strong>GPU Instances (P-type, G-type):</strong> Essential for
              deep learning with large datasets. P4d instances with NVIDIA A100
              GPUs offer 2.5x performance over previous generation. Use when
              training CNNs, transformers, or models with >100M parameters.
              Memory bandwidth often more important than compute capacity.
            </li>
            <li>
              <strong>AWS Trainium (Trn1):</strong> Purpose-built for training
              deep learning models with up to 50% cost savings over comparable
              GPU instances. Optimized for PyTorch and TensorFlow. Best for
              transformer models, computer vision, and NLP workloads at scale.
            </li>
            <li>
              <strong>Instance Selection Guidelines:</strong>
              <ul>
                <li>
                  Choose GPU when: training deep neural networks, working with
                  image/video data, using transformer architectures, or
                  requiring tensor operations at scale
                </li>
                <li>
                  Choose CPU when: running traditional ML algorithms, performing
                  feature engineering, handling small datasets, or optimizing
                  for cost on simpler models
                </li>
                <li>
                  Choose Trainium when: training large language models,
                  optimizing for cost-efficiency at scale, or deploying
                  production training pipelines for supported frameworks
                </li>
              </ul>
            </li>
            <li>
              <strong>Memory Considerations:</strong> Ensure instance memory can
              accommodate batch size × sample size × precision requirements. For
              distributed training, consider network bandwidth between nodes
              (EFA-enabled instances recommended).
            </li>
            <li>
              <strong>Storage Integration:</strong> Configure FSx for Lustre for
              high-throughput data loading or EFS for shared model artifacts
              across distributed training jobs.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Picking the right computer to do the learning:</p>
          <ul>
            <li>Choosing between different types of computers</li>
            <li>Using many computers together</li>
            <li>Making sure we don't spend too much money</li>
            <li>Setting up everything correctly</li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 5: AWS Container Services</h3>
        <p>Learn about AWS container services for ML:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Container orchestration for ML workloads:</p>
          <ul>
            <li>
              Docker Fundamentals: Image building, layer optimization, security
              best practices
            </li>
            <li>
              ECS Integration: Task definitions, service configuration, load
              balancing
            </li>
            <li>
              EKS Deployment: Kubernetes operators, autoscaling, resource
              management
            </li>
            <li>
              Monitoring: CloudWatch integration, metric collection, log
              aggregation
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Using special containers to organize our learning:</p>
          <ul>
            <li>Packaging our computer programs neatly</li>
            <li>Making sure everything works together</li>
            <li>Managing lots of containers at once</li>
            <li>Watching how well everything is working</li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>
          Lesson 6: Create A Training Job Using the Amazon SageMaker Console
        </h3>
        <p>Hands-on training job creation:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>SageMaker training job configuration:</p>
          <ul>
            <li>
              Data Configuration: S3 integration, input channels, file formats
            </li>
            <li>
              Resource Allocation: Instance selection, distributed training
              setup
            </li>
            <li>
              Hyperparameter Tuning: Search space definition, optimization
              objectives
            </li>
            <li>
              Monitoring Setup: Training metrics, instance utilization, logs
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Starting our first training project:</p>
          <ul>
            <li>Getting our learning data ready</li>
            <li>Setting up our learning computer</li>
            <li>Making our program learn better</li>
            <li>Watching how the learning goes</li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 7: Train a Model Using a SageMaker Built-in Algorithm</h3>
        <p>Using SageMaker's pre-built algorithms:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Leveraging built-in algorithms:</p>
          <ul>
            <li>
              Algorithm Selection: Use case matching, performance
              characteristics
            </li>
            <li>Data Preparation: Format requirements, feature engineering</li>
            <li>
              Training Configuration: Algorithm-specific parameters, resource
              allocation
            </li>
            <li>
              Model Artifacts: Output handling, model registry integration
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Using ready-made learning recipes:</p>
          <ul>
            <li>Picking the right learning recipe</li>
            <li>Preparing our information correctly</li>
            <li>Setting up the learning process</li>
            <li>Saving what our computer learned</li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 8: Train a Model Using SageMaker Script Mode</h3>
        <p>Custom training script development:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Script mode implementation details:</p>
          <ul>
            <li>
              Environment Setup: Container configuration, dependency management
            </li>
            <li>
              Script Structure: Entry points, training loop implementation
            </li>
            <li>
              Framework Integration: TensorFlow, PyTorch, and custom framework
              support
            </li>
            <li>Debugging Tools: Local testing, remote debugging setup</li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Writing our own learning instructions:</p>
          <ul>
            <li>Setting up our workspace</li>
            <li>Creating our learning program</li>
            <li>Using different learning tools</li>
            <li>Finding and fixing problems</li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 9: Methods to Reduce Training Time</h3>
        <p>Optimize training efficiency:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Training optimization techniques:</p>
          <ul>
            <li>Data Pipeline: Efficient data loading, caching strategies</li>
            <li>Distributed Training: Data parallelism, model parallelism</li>
            <li>
              Hardware Utilization: GPU optimization, mixed precision training
            </li>
            <li>
              Algorithm Optimization: Gradient accumulation, learning rate
              scheduling
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Making our learning faster:</p>
          <ul>
            <li>Getting information quickly</li>
            <li>Using many computers together</li>
            <li>Using special computer chips</li>
            <li>Making the learning smarter</li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 10: Integrating External Models into SageMaker</h3>
        <p>Working with external models:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>External model integration workflow:</p>
          <ul>
            <li>Model Conversion: Format compatibility, weight transfer</li>
            <li>
              Container Adaptation: Custom inference code, dependency management
            </li>
            <li>
              Deployment Configuration: Resource allocation, scaling policies
            </li>
            <li>
              Integration Testing: Endpoint validation, performance testing
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Using smart programs from other places:</p>
          <ul>
            <li>Making different programs work together</li>
            <li>Packaging programs correctly</li>
            <li>Setting up the program to work well</li>
            <li>Testing everything works properly</li>
          </ul>
        </div>
      </div>
    </div>

    <div class="section">
      <h2>Section 3: Modeling Approaches</h2>
      <div class="lesson">
        <h3>Lesson 5: AWS AI Services</h3>
        <p>Explore AWS AI Services including:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            AWS AI Services provide high-level APIs built on pre-trained models:
          </p>
          <ul>
            <li>
              Rekognition: Implements deep CNN architectures for image/video
              analysis, with built-in support for object detection, face
              recognition, and scene understanding
            </li>
            <li>
              Comprehend: Uses transformer-based NLP models for text analysis,
              sentiment analysis, and entity recognition
            </li>
            <li>
              Textract: Combines computer vision and NLP for intelligent OCR and
              document parsing
            </li>
            <li>
              Transcribe: Implements deep learning for automatic speech
              recognition with custom vocabulary support
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Let's see what special powers Amazon's tools have!</p>
          <ul>
            <li>
              A tool that can look at pictures and tell you what it sees (like
              playing I Spy)
            </li>
            <li>A tool that can read and understand words like a human</li>
            <li>A tool that can read papers and documents automatically</li>
            <li>
              A tool that can listen to someone talking and write down what they
              say
            </li>
          </ul>
        </div>
        <p>
          Reference:
          <a
            href="https://aws.amazon.com/machine-learning/ai-services/"
            class="aws-link"
            >AWS AI Services Documentation</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 6: Amazon SageMaker Built-In Algorithms</h3>
        <p>Deep dive into SageMaker's built-in algorithms:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            SageMaker provides optimized implementations of popular ML
            algorithms:
          </p>
          <ul>
            <li>
              Linear Learner: Implements L1/L2 regularization, automatic model
              tuning, and distributed training for linear models
            </li>
            <li>
              XGBoost: Gradient boosting framework with tree pruning, parallel
              training, and GPU acceleration
            </li>
            <li>
              DeepAR: RNN-based forecasting using autoregressive models with
              automatic feature engineering
            </li>
            <li>
              BlazingText: Word2Vec and text classification with distributed
              training and sub-word embeddings
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Let's learn about different ways computers can learn!</p>
          <ul>
            <li>
              A simple way to guess numbers or sort things (like drawing a line
              between two groups)
            </li>
            <li>
              A way to make better guesses by learning from mistakes (like
              getting better at a game by practicing)
            </li>
            <li>
              A special tool that can guess what will happen next (like
              predicting tomorrow's weather)
            </li>
            <li>
              A tool that can understand and sort different types of writing
            </li>
          </ul>
        </div>
        <p>
          Reference:
          <a
            href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html"
            class="aws-link"
            >SageMaker Built-in Algorithms</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 7: Amazon SageMaker JumpStart ML Solutions</h3>
        <p>Learn about SageMaker JumpStart:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            SageMaker JumpStart is AWS's model hub and transfer learning
            platform:
          </p>
          <ul>
            <li>
              Access to SOTA pre-trained models with PyTorch and TensorFlow
              implementations
            </li>
            <li>
              Automated deployment infrastructure with containerized inference
              endpoints
            </li>
            <li>
              Transfer learning workflows with custom fine-tuning scripts and
              hyperparameter optimization
            </li>
            <li>
              Production-ready solution templates with CI/CD pipelines and
              monitoring
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Imagine having a library of ready-to-use smart helpers!</p>
          <ul>
            <li>Use smart programs that other people have already taught</li>
            <li>Start using these helpers with just one button click</li>
            <li>Teach these programs new tricks for your specific needs</li>
            <li>Follow simple recipes to build your own smart programs</li>
          </ul>
        </div>
        <p>
          Reference:
          <a href="https://aws.amazon.com/sagemaker/jumpstart/" class="aws-link"
            >SageMaker JumpStart</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 8: Amazon Bedrock ML Solutions</h3>
        <p>Explore Amazon Bedrock capabilities:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Bedrock is AWS's foundation model service offering:</p>
          <ul>
            <li>
              Access to large language models and multimodal foundation models
              with different architectures and capabilities
            </li>
            <li>
              Custom fine-tuning pipelines with efficient few-shot learning and
              prompt engineering
            </li>
            <li>
              RESTful APIs and SDK integration with managed scaling and security
            </li>
            <li>
              Optimization techniques for latency, cost, and responsible AI
              practices
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Let's explore super-smart computer brains!</p>
          <ul>
            <li>
              Use special computer brains that can understand words, pictures,
              and more
            </li>
            <li>Teach these brains to help with your specific tasks</li>
            <li>
              Make it easy for your programs to talk to these smart brains
            </li>
            <li>
              Learn the best ways to use these smart helpers safely and
              efficiently
            </li>
          </ul>
        </div>
        <p>
          Reference:
          <a href="https://aws.amazon.com/bedrock/" class="aws-link"
            >Amazon Bedrock</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 9: Model Selection Considerations</h3>
        <p>Key factors in model selection:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Model selection involves analyzing multiple dimensions:</p>
          <ul>
            <li>
              Performance Metrics: Precision, recall, F1-score, AUC-ROC, and
              domain-specific metrics
            </li>
            <li>
              Resource Analysis: CPU/GPU requirements, memory footprint,
              inference latency, and operational costs
            </li>
            <li>
              Interpretability: SHAP values, LIME explanations, feature
              importance, and model-specific techniques
            </li>
            <li>
              Production Readiness: Scalability, monitoring capabilities,
              version control, and A/B testing support
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>How do we choose the best smart helper for our job?</p>
          <ul>
            <li>
              Check how well it can do the task (like getting a score on a test)
            </li>
            <li>Make sure we can afford to use it and it works fast enough</li>
            <li>See if it can explain why it makes certain choices</li>
            <li>Check if it can handle lots of work without getting tired</li>
          </ul>
        </div>
      </div>
    </div>

    <div class="section">
      <h2>Section 4: Model Refinement and Fine-Tuning</h2>
      <div class="lesson">
        <h3>Lesson 1: Understanding Model Fit</h3>
        <p>Master the concepts of model fit and performance evaluation:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            Model fit represents the balance between bias and variance in your
            model:
          </p>
          <ul>
            <li>
              Bias-Variance Tradeoff: Mathematical framework for understanding
              model complexity versus generalization ability. High bias leads to
              systematic errors, while high variance causes sensitivity to
              training data fluctuations.
            </li>
            <li>
              Evaluation Metrics: Quantitative measures including R-squared,
              adjusted R-squared, AIC, BIC for regression; precision-recall
              curves and confusion matrices for classification.
            </li>
            <li>
              Cross-Validation Strategies: k-fold, stratified, leave-one-out,
              and time-series specific validation techniques to estimate
              generalization performance.
            </li>
            <li>
              Learning Curves: Diagnostic plots showing training and validation
              error as functions of training set size or training iterations to
              identify bias-variance issues.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>How do we know if our computer is learning correctly?</p>
          <ul>
            <li>
              Making sure our computer isn't memorizing answers but actually
              understanding patterns
            </li>
            <li>
              Using special scorecards to check how well our computer is doing
            </li>
            <li>Testing our computer on information it hasn't seen before</li>
            <li>
              Looking at special pictures that show how our computer's learning
              is improving
            </li>
          </ul>
        </div>
        <p>
          Reference:
          <a
            href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-evaluation.html"
            class="aws-link"
            >SageMaker Model Evaluation</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 2: Overfitting and Underfitting</h3>
        <p>Identify and address common model fitting problems:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            Understanding the mathematical and statistical foundations of model
            fitting issues:
          </p>
          <ul>
            <li>
              Overfitting: Occurs when model complexity exceeds what the data
              supports, resulting in high variance. The model captures noise
              rather than signal, exhibiting low training error but high test
              error. Mathematically represented as minimizing empirical risk
              without sufficient regularization.
            </li>
            <li>
              Underfitting: Results from insufficient model capacity (high
              bias), where the model fails to capture underlying patterns. Both
              training and test errors remain high. Often occurs when using
              linear models for non-linear relationships.
            </li>
            <li>
              Detection Methods: Quantitative approaches including train-test
              error gap analysis, learning curves, validation curves, and
              statistical tests for model comparison.
            </li>
            <li>
              Mitigation Strategies: Regularization techniques (L1, L2,
              dropout), ensemble methods, feature engineering, and architecture
              search to achieve optimal model complexity.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Helping our computer learn just the right amount:</p>
          <ul>
            <li>
              Overfitting: When the computer memorizes examples instead of
              learning general rules (like memorizing test answers without
              understanding the subject)
            </li>
            <li>
              Underfitting: When the computer's learning is too simple to
              understand complicated patterns (like using addition to solve
              multiplication problems)
            </li>
            <li>
              Finding clues that tell us if our computer is learning too much or
              too little
            </li>
            <li>
              Special tricks to help our computer learn better (like giving it
              just the right amount of information)
            </li>
          </ul>
        </div>
        <p>
          Reference:
          <a
            href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-fit-underfitting-vs-overfitting.html"
            class="aws-link"
            >Understanding Model Fit: Underfitting vs. Overfitting</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 3: Model Fine-Tuning Techniques</h3>
        <p>Advanced approaches to refine model performance:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Systematic approaches to model optimization and fine-tuning:</p>
          <ul>
            <li>
              Hyperparameter Optimization: Bayesian optimization, grid search,
              random search, and evolutionary algorithms for efficient
              hyperparameter space exploration. Mathematical foundations of
              acquisition functions and surrogate models.
            </li>
            <li>
              Transfer Learning: Theoretical basis for knowledge transfer across
              domains, including feature extraction, fine-tuning strategies, and
              domain adaptation techniques. Mathematical analysis of
              representation learning and task similarity.
            </li>
            <li>
              Regularization Methods: Advanced techniques including weight
              decay, early stopping, dropout, batch normalization, and data
              augmentation with their theoretical justifications.
            </li>
            <li>
              Ensemble Learning: Theoretical foundations of model combination
              methods including bagging, boosting, stacking, and Bayesian model
              averaging with analysis of bias-variance decomposition.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Making our smart computer even better:</p>
          <ul>
            <li>
              Finding the perfect settings for our computer's learning (like
              adjusting the difficulty level in a game)
            </li>
            <li>
              Teaching our computer new tricks based on what it already knows
              (like learning a new sport when you already know a similar one)
            </li>
            <li>
              Special training methods that help the computer avoid making
              mistakes
            </li>
            <li>
              Using a team of smart computers that work together (like asking
              several friends for advice instead of just one)
            </li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 4: SageMaker Automatic Model Tuning</h3>
        <p>Leverage AWS tools for efficient model optimization:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>SageMaker's automated hyperparameter optimization capabilities:</p>
          <ul>
            <li>
              Bayesian Optimization: Implementation details of SageMaker's
              implementation of Bayesian optimization, including the use of
              Gaussian Process surrogate models and acquisition functions to
              efficiently explore the hyperparameter space.
            </li>
            <li>
              Search Strategies: Random search, grid search, and Hyperband
              approaches available in SageMaker AMT, with comparative analysis
              of efficiency and convergence properties.
            </li>
            <li>
              Parallel Training: Technical implementation of distributed
              hyperparameter optimization, resource allocation strategies, and
              early stopping mechanisms.
            </li>
            <li>
              Custom Objective Metrics: Configuration of custom evaluation
              metrics, multi-metric optimization, and constraint handling for
              complex model optimization scenarios.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Let Amazon help find the best settings for our computer:</p>
          <ul>
            <li>
              Using smart search tools to find the perfect settings without
              trying every possibility
            </li>
            <li>
              Testing many different settings at the same time to save time
            </li>
            <li>Automatically stopping tests that aren't working well</li>
            <li>
              Creating our own way to measure success based on what's important
              to us
            </li>
          </ul>
        </div>
        <p>
          Reference:
          <a
            href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html"
            class="aws-link"
            >SageMaker Automatic Model Tuning</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 5: Managing Model Size and Optimization</h3>
        <p>Understanding and controlling model complexity:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>
            Model size optimization techniques and their theoretical
            foundations:
          </p>
          <ul>
            <li>
              Model Size Factors: Architectural determinants of model complexity
              including layer dimensions, parameter count, activation functions,
              and computational graph structure. Analysis of inference latency
              versus accuracy tradeoffs.
            </li>
            <li>
              Pruning Techniques: Magnitude-based, structured, and dynamic
              pruning methods. Mathematical basis for sensitivity analysis and
              importance scoring of neural network parameters.
            </li>
            <li>
              Quantization: Post-training and quantization-aware training
              approaches. Numerical analysis of fixed-point arithmetic versus
              floating-point precision and error propagation.
            </li>
            <li>
              Knowledge Distillation: Teacher-student model compression
              framework, soft target optimization, and feature-based
              distillation techniques with their information-theoretic
              foundations.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Making our smart computer smaller and faster:</p>
          <ul>
            <li>
              Understanding what makes our computer program large or small
            </li>
            <li>
              Removing parts of our computer's brain that aren't really needed
            </li>
            <li>Using simpler numbers to make calculations faster</li>
            <li>Having a bigger computer teach a smaller one its knowledge</li>
          </ul>
        </div>
        <p>
          Reference:
          <a
            href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-compiler.html"
            class="aws-link"
            >SageMaker Neo Model Optimization</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 6: Pre-trained Model Fine-tuning</h3>
        <p>Leveraging foundation models for custom applications:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Advanced transfer learning and fine-tuning methodologies:</p>
          <ul>
            <li>
              Foundation Models: Architectural properties of large pre-trained
              models including transformers, diffusion models, and multimodal
              architectures. Analysis of emergent capabilities and scaling laws.
            </li>
            <li>
              Fine-tuning Strategies: Parameter-efficient tuning methods
              including adapter modules, LoRA (Low-Rank Adaptation), prompt
              tuning, and full fine-tuning with their mathematical foundations
              and computational efficiency analysis.
            </li>
            <li>
              Domain Adaptation: Techniques for addressing domain shift
              including adversarial approaches, self-supervised adaptation, and
              consistency regularization methods.
            </li>
            <li>
              Catastrophic Forgetting: Theoretical understanding of knowledge
              retention challenges in neural networks and mitigation strategies
              including regularization-based, rehearsal-based, and
              architecture-based approaches.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Teaching already smart computers to do specific tasks for us:</p>
          <ul>
            <li>
              Starting with computers that already know a lot about the world
            </li>
            <li>
              Teaching them our specific task without having to start from
              scratch
            </li>
            <li>Helping them understand our special type of information</li>
            <li>
              Making sure they don't forget what they already learned while
              learning new things
            </li>
          </ul>
        </div>
      </div>

      <div class="lesson">
        <h3>Lesson 7: AWS Tools for Pre-trained Model Fine-tuning</h3>
        <p>Using AWS services for efficient model refinement:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Technical implementation of fine-tuning on AWS platforms:</p>
          <ul>
            <li>
              SageMaker JumpStart: Low-code API for foundation model access and
              fine-tuning, including technical details of model hosting,
              incremental training workflows, and hyperparameter specifications
              for various model families.
            </li>
            <li>
              Amazon Bedrock: Serverless foundation model service architecture,
              model access patterns, fine-tuning API specifications, and
              throughput optimization strategies.
            </li>
            <li>
              Custom Dataset Preparation: Technical requirements for fine-tuning
              datasets, including format specifications, preprocessing
              pipelines, and validation methodologies for different model
              architectures.
            </li>
            <li>
              Deployment Strategies: Configuration options for deploying
              fine-tuned models, including endpoint configuration, auto-scaling
              policies, and inference optimization techniques.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>
            Amazon's special tools that make teaching smart computers easier:
          </p>
          <ul>
            <li>
              SageMaker JumpStart: A library of ready-to-use smart computers we
              can teach new things
            </li>
            <li>
              Amazon Bedrock: Super-smart computer brains we can use without
              managing complicated computers
            </li>
            <li>
              Preparing our own information in a way these smart computers can
              understand
            </li>
            <li>
              Setting up our newly trained smart computer so everyone can use it
            </li>
          </ul>
        </div>
        <p>
          Reference:
          <a href="https://aws.amazon.com/sagemaker/jumpstart/" class="aws-link"
            >SageMaker JumpStart</a
          >
          |
          <a href="https://aws.amazon.com/bedrock/" class="aws-link"
            >Amazon Bedrock</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 8: Model Versioning and Registry</h3>
        <p>Managing model lifecycle with SageMaker Model Registry:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Enterprise-grade model governance and versioning:</p>
          <ul>
            <li>
              Model Registry Architecture: Component structure of SageMaker
              Model Registry, metadata schema design, and integration points
              with MLOps pipelines including CI/CD systems.
            </li>
            <li>
              Version Control: Implementation of semantic versioning for models,
              immutable artifacts management, and lineage tracking including
              dataset, algorithm, and hyperparameter provenance.
            </li>
            <li>
              Model Approval Workflows: Programmatic implementation of approval
              state machines, integration with notification systems, and
              implementation of approval-triggered deployment patterns.
            </li>
            <li>
              Governance Features: Technical implementation of model
              documentation, access control patterns, audit logging, and
              compliance validation workflows.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Keeping track of all our different smart computers:</p>
          <ul>
            <li>
              Giving each version of our computer a special name and number
            </li>
            <li>Saving information about how each computer was trained</li>
            <li>
              Having a system for approving which computers are good enough to
              use
            </li>
            <li>
              Creating a history book that shows all the changes we've made
            </li>
          </ul>
        </div>
        <p>
          Reference:
          <a
            href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html"
            class="aws-link"
            >SageMaker Model Registry</a
          >
        </p>
      </div>

      <div class="lesson">
        <h3>Lesson 9: Practical Exercise - Model Refinement Pipeline</h3>
        <p>Implement an end-to-end model refinement workflow:</p>

        <div class="explanation cs-student">
          <h4>For CS Students:</h4>
          <p>Comprehensive implementation of a model refinement pipeline:</p>
          <ul>
            <li>
              Baseline Evaluation: Establishing performance benchmarks using
              statistically rigorous evaluation protocols, including stratified
              sampling, confidence intervals, and significance testing.
            </li>
            <li>
              Systematic Refinement: Implementing an iterative improvement
              process with controlled experiments for hyperparameter
              optimization, feature engineering, ensemble construction, and
              model compression.
            </li>
            <li>
              Pipeline Automation: Programmatic orchestration using SageMaker
              Pipelines, including DAG definition, conditional execution,
              caching strategies, and artifact management.
            </li>
            <li>
              Performance Validation: Implementing rigorous A/B testing
              methodologies, champion-challenger model evaluation, and
              monitoring protocols for detecting performance degradation.
            </li>
          </ul>
        </div>

        <div class="explanation simple">
          <h4>Simple Explanation:</h4>
          <p>Building a step-by-step plan to make our computer smarter:</p>
          <ul>
            <li>First checking how smart our computer is to begin with</li>
            <li>
              Trying different ways to make it smarter, one step at a time
            </li>
            <li>
              Creating a recipe that automatically makes our computer better
            </li>
            <li>
              Carefully comparing the new version to the old one to make sure
              it's really improved
            </li>
          </ul>
        </div>

        <div class="exercise">
          <h4>Hands-on Exercise:</h4>
          <p>In this exercise, you will:</p>
          <ol>
            <li>Evaluate a baseline model for bias and performance issues</li>
            <li>Apply regularization techniques to address overfitting</li>
            <li>
              Implement hyperparameter tuning to optimize model performance
            </li>
            <li>Create an ensemble of models to improve prediction accuracy</li>
            <li>
              Register and version the refined model in SageMaker Model Registry
            </li>
          </ol>
          <p>
            <a href="#" class="exercise-link">Access the notebook template</a>
            to complete this exercise.
          </p>
        </div>
      </div>

      <div class="mt-8 bg-white shadow rounded-lg p-6">
        <h4 class="text-xl font-semibold text-gray-800 mb-6">
          Knowledge Check: Model Refinement
        </h4>
        <div class="space-y-6">
          <div class="bg-gray-50 rounded-lg p-6">
            <p class="text-gray-800 font-medium mb-4">
              1. Which of the following is a sign of model overfitting?
            </p>
            <form id="quiz-form-refinement-1">
              <ul class="space-y-3">
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r1_a"
                    name="q_refinement_1"
                    value="a"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r1_a" class="ml-3 text-gray-700"
                    >High error on both training and test data</label
                  >
                </li>
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r1_b"
                    name="q_refinement_1"
                    value="b"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r1_b" class="ml-3 text-gray-700"
                    >Low error on training data but high error on test
                    data</label
                  >
                </li>
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r1_c"
                    name="q_refinement_1"
                    value="c"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r1_c" class="ml-3 text-gray-700"
                    >Equal error on both training and test data</label
                  >
                </li>
              </ul>
              <button
                type="submit"
                class="mt-4 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2"
              >
                Submit Answer
              </button>
              <div id="q_r1-feedback" class="mt-3 hidden"></div>
            </form>
          </div>

          <div class="bg-gray-50 rounded-lg p-6">
            <p class="text-gray-800 font-medium mb-4">
              2. Which technique is NOT typically used for preventing
              overfitting?
            </p>
            <form id="quiz-form-refinement-2">
              <ul class="space-y-3">
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r2_a"
                    name="q_refinement_2"
                    value="a"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r2_a" class="ml-3 text-gray-700"
                    >L2 Regularization</label
                  >
                </li>
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r2_b"
                    name="q_refinement_2"
                    value="b"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r2_b" class="ml-3 text-gray-700"
                    >Increasing model complexity</label
                  >
                </li>
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r2_c"
                    name="q_refinement_2"
                    value="c"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r2_c" class="ml-3 text-gray-700">Dropout</label>
                </li>
              </ul>
              <button
                type="submit"
                class="mt-4 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2"
              >
                Submit Answer
              </button>
              <div id="q_r2-feedback" class="mt-3 hidden"></div>
            </form>
          </div>

          <div class="bg-gray-50 rounded-lg p-6">
            <p class="text-gray-800 font-medium mb-4">
              3. Which hyperparameter tuning strategy is most computationally
              efficient for exploring large hyperparameter spaces?
            </p>
            <form id="quiz-form-refinement-3">
              <ul class="space-y-3">
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r3_a"
                    name="q_refinement_3"
                    value="a"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r3_a" class="ml-3 text-gray-700"
                    >Grid Search</label
                  >
                </li>
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r3_b"
                    name="q_refinement_3"
                    value="b"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r3_b" class="ml-3 text-gray-700"
                    >Bayesian Optimization</label
                  >
                </li>
                <li class="flex items-center">
                  <input
                    type="radio"
                    id="q_r3_c"
                    name="q_refinement_3"
                    value="c"
                    class="h-4 w-4 text-blue-600 border-gray-300 focus:ring-blue-500"
                  />
                  <label for="q_r3_c" class="ml-3 text-gray-700"
                    >Manual Tuning</label
                  >
                </li>
              </ul>
              <button
                type="submit"
                class="mt-4 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2"
              >
                Submit Answer
              </button>
              <div id="q_r3-feedback" class="mt-3 hidden"></div>
            </form>
          </div>
        </div>
      </div>
    </div>
    <!-- Add this line where fyou want section5_complete.html to be included -->
    <div id="section5-content"></div>

    <!-- Add this script at the end of the body tag -->
    <script>
      fetch("section5_complete.html")
        .then((response) => response.text())
        .then((data) => {
          document.getElementById("section5-content").innerHTML = data;
        })
        .catch((error) => console.error("Error loading section5:", error));
    </script>
    <div class="lesson">
      <h3>Lesson: Selecting Model Deployment Infrastructure</h3>
      <p>Choosing the right deployment infrastructure for ML models:</p>

      <div class="explanation cs-student">
        <h4>For CS Students:</h4>
        <p>Technical considerations for model deployment infrastructure:</p>
        <ul>
          <li>
            Serverless Deployment: AWS Lambda integration patterns, cold/warm
            start optimization, memory configuration, and execution time
            constraints. Analysis of cost versus latency tradeoffs.
          </li>
          <li>
            Container-based Deployment: Docker containerization strategies,
            ECS/EKS orchestration, auto-scaling configurations, and resource
            optimization. Implementation of health checks and rolling updates.
          </li>
          <li>
            Real-time Inference: SageMaker real-time endpoints architecture,
            instance selection optimization, multi-model endpoints, and traffic
            routing patterns. Analysis of concurrent request handling and queue
            management.
          </li>
          <li>
            Batch Transform: Implementation of batch processing pipelines,
            parallel processing strategies, data chunking optimizations, and
            resource utilization patterns. Cost optimization for large-scale
            inference.
          </li>
        </ul>
      </div>

      <div class="explanation simple">
        <h4>Simple Explanation:</h4>
        <p>Choosing how to run our smart computer in the real world:</p>
        <ul>
          <li>
            Quick and simple setup that only runs when needed (like turning on a
            light)
          </li>
          <li>
            Running in special boxes that can grow or shrink based on needs
            (like having more delivery trucks during busy times)
          </li>
          <li>
            Always-ready systems for immediate answers (like having a customer
            service desk)
          </li>
          <li>
            Processing lots of information all at once (like sorting mail in a
            post office)
          </li>
        </ul>
      </div>
      <p>
        Reference:
        <a
          href="https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html"
          class="aws-link"
          >SageMaker Deployment Options</a
        >
      </p>
    </div>
    <script>
      // Quiz functionality
      document.addEventListener("DOMContentLoaded", function () {
        // Get all quiz forms
        const quizForms = document.querySelectorAll(".quiz-form");

        // Handle form submission
        quizForms.forEach((form) => {
          form.addEventListener("submit", function (e) {
            e.preventDefault();

            // Get the correct answer
            const correctAnswer = this.dataset.correctAnswer;

            // Get the selected answer
            const selectedAnswer = Array.from(
              this.querySelectorAll('input[type="radio"]:checked')
            ).map((input) => input.value)[0];

            // Show feedback
            const feedback = this.querySelector(".feedback");
            if (selectedAnswer === correctAnswer) {
              feedback.textContent = "Correct!";
              feedback.style.color = "green";
            } else {
              feedback.textContent = "Incorrect. Try again!";
              feedback.style.color = "red";
            }

            // Reset form after 2 seconds
            setTimeout(() => {
              this.reset();
              feedback.textContent = "";
            }, 2000);
          });
        });
      });
    </script>
  </body>
</html>
